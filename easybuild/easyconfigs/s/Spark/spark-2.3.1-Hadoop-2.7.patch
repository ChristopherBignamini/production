diff -Nru spark-2.3.1-bin-hadoop2.7.orig/sbin/slaves.sh spark-2.3.1-bin-hadoop2.7/sbin/slaves.sh
--- spark-2.3.1-bin-hadoop2.7.orig/sbin/slaves.sh	2018-06-01 22:49:09.000000000 +0200
+++ spark-2.3.1-bin-hadoop2.7/sbin/slaves.sh	2018-11-28 17:26:13.000000000 +0100
@@ -87,13 +87,20 @@
   SPARK_SSH_OPTS="-o StrictHostKeyChecking=no"
 fi
 
+DEPLOY="ssh"
+SPARK_SSH_OPTS="-p 2222 -o StrictHostKeyChecking=no"
+SPARK_var=$(env | grep SPARK)
+JAVA_var=$(env | grep JAVA)
+
 for slave in `echo "$HOSTLIST"|sed  "s/#.*$//;/^$/d"`; do
   if [ -n "${SPARK_SSH_FOREGROUND}" ]; then
-    ssh $SPARK_SSH_OPTS "$slave" $"${@// /\\ }" \
+    # CSCS: ssh $SPARK_SSH_OPTS "$slave" $"${@// /\\ }" \
+	$DEPLOY $SPARK_SSH_OPTS "$slave" $"${@// /\\ }" \
       2>&1 | sed "s/^/$slave: /"
   else
-    ssh $SPARK_SSH_OPTS "$slave" $"${@// /\\ }" \
-      2>&1 | sed "s/^/$slave: /" &
+    # CSCS: ssh $SPARK_SSH_OPTS "$slave" $"${@// /\\ }" \
+    # CSCS:   2>&1 | sed "s/^/$slave: /" &
+	$DEPLOY $SPARK_SSH_OPTS "$slave" $SPARK_var $JAVA_var  $"${@// /\\ }" 2>&1 | sed "s/^/$slave: /" &  
   fi
   if [ "$SPARK_SLAVE_SLEEP" != "" ]; then
     sleep $SPARK_SLAVE_SLEEP
diff -Nru spark-2.3.1-bin-hadoop2.7.orig/sbin/spark-daemon.sh spark-2.3.1-bin-hadoop2.7/sbin/spark-daemon.sh
--- spark-2.3.1-bin-hadoop2.7.orig/sbin/spark-daemon.sh	2018-06-01 22:49:09.000000000 +0200
+++ spark-2.3.1-bin-hadoop2.7/sbin/spark-daemon.sh	2018-11-28 17:11:11.000000000 +0100
@@ -115,7 +115,8 @@
 fi
 
 # some variables
-log="$SPARK_LOG_DIR/spark-$SPARK_IDENT_STRING-$command-$instance-$HOSTNAME.out"
+# CSCS: log="$SPARK_LOG_DIR/spark-$SPARK_IDENT_STRING-$command-$instance-$HOSTNAME.out"
+log="$SPARK_LOG_DIR/spark-$SPARK_IDENT_STRING-$command-$instance-$(hostname).out"
 pid="$SPARK_PID_DIR/spark-$SPARK_IDENT_STRING-$command-$instance.pid"
 
 # Set default scheduling priority
diff -Nru spark-2.3.1-bin-hadoop2.7.orig/sbin/start-slaves.sh spark-2.3.1-bin-hadoop2.7/sbin/start-slaves.sh
--- spark-2.3.1-bin-hadoop2.7.orig/sbin/start-slaves.sh	2018-06-01 22:49:09.000000000 +0200
+++ spark-2.3.1-bin-hadoop2.7/sbin/start-slaves.sh	2018-11-28 17:14:14.000000000 +0100
@@ -43,4 +43,5 @@
 fi
 
 # Launch the slaves
-"${SPARK_HOME}/sbin/slaves.sh" cd "${SPARK_HOME}" \; "${SPARK_HOME}/sbin/start-slave.sh" "spark://$SPARK_MASTER_HOST:$SPARK_MASTER_PORT"
+# CSCS: "${SPARK_HOME}/sbin/slaves.sh" cd "${SPARK_HOME}" \; "${SPARK_HOME}/sbin/start-slave.sh" "spark://$SPARK_MASTER_HOST:$SPARK_MASTER_PORT"
+"${SPARK_HOME}/sbin/slaves.sh" "${SPARK_HOME}/sbin/start-slave.sh" "${SPARKURL}"
diff -Nru spark-2.3.1-bin-hadoop2.7.orig/sbin/stop-slaves.sh spark-2.3.1-bin-hadoop2.7/sbin/stop-slaves.sh
--- spark-2.3.1-bin-hadoop2.7.orig/sbin/stop-slaves.sh	2018-06-01 22:49:09.000000000 +0200
+++ spark-2.3.1-bin-hadoop2.7/sbin/stop-slaves.sh	2018-11-28 17:15:06.000000000 +0100
@@ -25,4 +25,5 @@
 
 . "${SPARK_HOME}/bin/load-spark-env.sh"
 
-"${SPARK_HOME}/sbin/slaves.sh" cd "${SPARK_HOME}" \; "${SPARK_HOME}/sbin"/stop-slave.sh
+# CSCS: "${SPARK_HOME}/sbin/slaves.sh" cd "${SPARK_HOME}" \; "${SPARK_HOME}/sbin"/stop-slave.sh
+"${SPARK_HOME}/sbin/slaves.sh" "${SPARK_HOME}/sbin"/stop-slave.sh
